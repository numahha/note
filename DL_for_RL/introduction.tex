\section{入門：多層パーセプトロン (MLP) を用いた回帰}
\subsection{２層パーセプトロン}
\label{subsec:2layerNN}
\paragraph{2層NN順伝播．}
$n$番目のデータに対して，入力$\vx_n\in\mathbb{R}^{H_0}$，出力$\vy_n\in\mathbb{R}^{D}$，重みパラメータ$\vW^{(1)}\in\mathbb{R}^{H_1\times H_0}$，$\vW^{(2)}\in\mathbb{R}^{D\times H_1}$，活性化関数$\phi(\cdot)$，正規ノイズ$\vepsilon_n\mathbb{R}^{D}$として，次のモデルを考える．
\begin{align*}
 y_{n,d} = \sum_{h_1=1}^{H_1}w^{(2)}_{d,h_1}\phi\left( \sum_{h_0=1}^{H_0}w^{(1)}_{h_1,h_0}x_{n,h_0} \right) + \epsilon_{n,d}.
\end{align*}
あるいはベクトル表記で
\begin{align*}
 \vy_n
 =
 \vW^{(2)} \vphi.\left( \vW\vx_n \right) + \vepsilon_n
\end{align*}
ここで，$ \vphi.(\cdot)$は要素ごとに活性化関数を適用してベクトルにしたものを意味する．
2層だと上の書き方で十分だが，多層に拡張する際には次の表記の方が使いやすい．
\begin{align*}
 \vz^{(0)}_n &= \vx_n
 \\
 \va^{(1)}_n &= \vW^{(1)}\vz^{(0)}_n
 \\
 \vz^{(1)}_n &= \vphi.(\va^{(1)}_n)
 \\
 \va^{(2)}_n &= \vW^{(2)}\vz^{(1)}_n
 \\
 \vy_n &= \va^{(2)}_n + \vepsilon_n
\end{align*}


\paragraph{2層NN逆伝播．}
パラメータの集合を$\vW$，学習データ数を$N$とする．誤差関数を次で設計したとする．
\begin{align*}
 E_n(\vW) &= \frac{1}{2}\sum_{d=1}^D (y_{n,d}-a^{(2)}_{n,d})^2
\\
 E(\vW) &= \sum_{n=1}^N E_n(\vW)
\end{align*}
この時，$\phi'$は活性化関数の微分として，次のように書ける．
\begin{align*}
 \frac{\partial E_n(\vW)}{\partial w^{(2)}_{d,h_1}}
 &=
 \frac{\partial E_n(\vW)}{\partial a^{(2)}_{n,d}}  \frac{\partial a^{(2)}_{n,d}}{\partial w^{(2)}_{d,h_1}}
=
 \left[ y_{n,d}-a^{(2)}_{n,d}\right] \left[ z^{(1)}_{n,h_1}\right]
=\left[\delta^{(2)}_{n,d}\right] \left[ z^{(1)}_{n,h_1}\right]
=\delta^{(2)}_{n,d} z^{(1)}_{n,h_1}
\\
\frac{\partial E_n(\vW)}{\partial w^{(1)}_{h_1,h_0}}
&=
\left\{
\sum_{d=1}^D
\frac{\partial E_n(\vW)}{\partial a^{(2)}_{n,d}}
\frac{\partial a^{(2)}_{n,d}}{\partial a^{(1)}_{n,h_1}}
\right\}
\frac{\partial a^{(1)}_{n,h_1}}{\partial w^{(1)}_{h_1,h_0}}
=
\left\{
\sum_{d=1}^D\delta^{(2)}_{n,d}
\frac{\partial a^{(2)}_{n,d}}{\partial a^{(1)}_{n,h_1}}
\right\}
\frac{\partial a^{(1)}_{n,h_1}}{\partial w^{(1)}_{h_1,h_0}}
\\
&=
\left\{
\sum_{d=1}^D\delta^{(2)}_{n,d}
\left[ \frac{\partial}{\partial a^{(1)}_{n,h_1}}\sum_{h_1'=1}^{H_1}w^{(2)}_{d,h_1'}z^{(1)}_{n,h_1'}\right]
\right\}
\left[\frac{\partial}{\partial w^{(1)}_{h_1,h_0}}\sum_{h_0'=1}^{H_0} w^{(1)}_{h_1,h_0'}z^{(0)}_{n,h_0'}\right]
\\
&=
\left\{
\sum_{d=1}^D\delta^{(2)}_{n,d}
\left[ w^{(2)}_{d,h_1} \frac{\partial z^{(1)}_{n,h_1}}{\partial a^{(1)}_{n,h_1}} \right]
\right\}
\left[z^{(0)}_{n,h_0}\right]
=
\left\{
\sum_{d=1}^D\delta^{(2)}_{n,d}
\left[ w^{(2)}_{d,h_1} \phi'(a^{(1)}_{n,h_1}) \right]
\right\}
\left[z^{(0)}_{n,h_0}\right]
\\
&=
\left\{
\phi'(a^{(1)}_{n,h_1}) \sum_{d=1}^D\delta^{(2)}_{n,d} w^{(2)}_{d,h_1}
\right\}
\left[z^{(0)}_{n,h_0}\right]
\\
&=
\left[ \delta^{(1)}_{n,h_1} \right]
\left[z^{(0)}_{n,h_0}\right]
=
\delta^{(1)}_{n,h_1}
z^{(0)}_{n,h_0}
\end{align*}

\paragraph{更新．}
全てのパラメータに対する微分が上で計算できたので，勾配法で更新することができる．
\begin{align*}
 w_{i,j}^{(\ell)} - \eta \frac{\partial E(\vW)}{\partial w_{i,j}^{(\ell)}}
 =
 w_{i,j}^{(\ell)} - \eta \sum_{n=1}^N \frac{\partial E_n(\vW)}{\partial w_{i,j}^{(\ell)}}
\end{align*}

\paragraph{まとめ．}
\begin{itemize}
\item 順伝播で全ての$\va$と$\vz$を計算．
\item 逆伝播で全ての$\vdelta$を計算．
\item 勾配法．
\end{itemize}

\subsection{多層パーセプトロン}
同様にして導出できる．
\paragraph{MLP順伝播．}
\begin{align*}
 \vz^{(\ell)}_n &=
 \left\{
     \begin{array}{ll}
       \vx_n & \mbox{if }\ell=0 \\
       \vphi.(\va^{(\ell)}_n) & \mbox{if }\ell \in \{1,\cdots,L-1 \}
     \end{array}
   \right.
   \\
 \va^{(\ell)}_n &= \vW^{(\ell)}\vz^{(\ell-1)}_n,~~~\ell=1,\cdots,L
 \\
 \vy_n &= \va^{(L)}_n + \vepsilon_n
\end{align*}

\paragraph{MLP逆伝播．}
\begin{align*}
 \frac{\partial E_n(\vW)}{\partial w^{(L)}_{d,h_1}}
 &=
 \left[ \frac{\partial E_n(\vW)}{\partial a^{(L)}_{n,d}} \right] \left[ z^{(L-1)}_{n,h_{L-1}}\right]
=\delta^{(L)}_{n,d}z^{(L-1)}_{n,h_{L-1}}
\\
\frac{\partial E_n(\vW)}{\partial w^{(\ell)}_{h_\ell,h_{\ell-1}}}
&=
\left[
\phi'(a^{(\ell)}_{n,h_\ell}) \sum_{h_{\ell+1}=1}^{H_{\ell+1}}\delta^{(\ell+1)}_{n,h_{\ell+1}} w^{(\ell+1)}_{h_{\ell+1},h_\ell}
\right]
\left[z^{(\ell-1)}_{n,h_{\ell-1}}\right]
=
\delta^{(\ell)}_{n,h_\ell}
z^{(\ell-1)}_{n,h_{\ell-1}}
,~~~\ell=1,\cdots,L-1
\end{align*}
